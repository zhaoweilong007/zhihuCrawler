# 如何入门 Python 爬虫？
- 点赞数：6463
- 更新时间：2020年02月10日11时27分03秒
- 回答url：https://www.zhihu.com/question/20899988/answer/58388759
<body>
 <p data-pid="IbgxBuFi">看了大部分回答不禁叹口气，主要是因为看到很多大牛在回答像“如何入门爬虫”这种问题的时候，一如当年学霸讲解题目，跳步无数，然后留下一句“不就是这样推嘛”，让一众小白菜鸟一脸懵逼。。作为一个0起步（之前连python都不会），目前总算掌握基础，开始向上进阶的菜鸟，深知其中的不易，所以我会在这个回答里，尽可能全面、细节地分享给大家从0学习爬虫的各种步骤，如果对你有帮助，请点赞~</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-1a5d791ff27dfcba511419622572ca16_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="430" data-original-token="v2-652f70071591757ddd1b4f496bffdafd" data-default-watermark-src="https://picx.zhimg.com/50/v2-7332a5ae4814647058c87970c1378a01_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="584" data-original="https://picx.zhimg.com/v2-1a5d791ff27dfcba511419622572ca16_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="c-J9Dlp3">-------------------------------------------------------------------------------------------------<br><b>#我要写爬虫！</b> <b>#Ver.1.5 </b> <b>#Based on: Python 2.7</b><br><b>#Author:高野良</b><br>
  #<b>原创内容，转载请注明出处</b></p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="o31Ks4-2"><b><u>首先！你要对爬虫有个明确的认识，这里引用毛主席的思想：</u></b></p>
 <blockquote data-pid="rQLDMiz-">
  <b>在战略上藐视：</b>
 </blockquote>
 <ul>
  <li data-pid="H7lH-7kq"><b>“所有网站皆可爬”：</b>互联网的内容都是人写出来的，而且都是偷懒写出来的（不会第一页是a，下一页是8），所以肯定有规律，这就给人有了爬取的可能，可以说，天下没有不能爬的网站<br></li>
  <li data-pid="VxoVOstG"><b>“框架不变”：</b>网站不同，但是原理都类似，大部分爬虫都是从 <b>发送请求——获得页面——解析页面——下载内容——储存内容</b> 这样的流程来进行，只是用的工具不同</li>
 </ul>
 <p data-pid="3yYXV-Wr"><b><u>在战术上重视：</u></b></p>
 <ul>
  <li data-pid="d9v8XNTY"><b>持之以恒，戒骄戒躁：</b>对于初学入门，不可轻易自满，以为爬了一点内容就什么都会爬了，爬虫虽然是比较简单的技术，但是往深学也是没有止境的（比如搜索引擎等）！只有不断尝试，刻苦钻研才是王道！（为何有种小学作文即视感）</li>
 </ul>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="QfMsVR1z">||<br>
   ||<br>
   V</p>
 <p data-pid="QjIdRpWR"><b><u>然后，你需要一个宏伟的目标，来让你有持续学习的动力（没有实操项目，真的很难有动力）</u></b></p>
 <blockquote data-pid="VvPBxo7y">
  我要爬整个豆瓣！...
  <br>
  我要爬整个xx社区！
  <br>
  我要爬知乎各种妹子的联系方式*&amp;^#%^$#
 </blockquote>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/9264555e01047baf9f88b1919d21c5ab_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="580" data-rawheight="287" data-original-token="9264555e01047baf9f88b1919d21c5ab" class="origin_image zh-lightbox-thumb" width="580" data-original="https://picx.zhimg.com/9264555e01047baf9f88b1919d21c5ab_r.jpg?source=1940ef5c">
 </figure>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="oSKcw9wi">||<br>
   ||<br>
   V</p>
 <p data-pid="RKTECQ9S"><b><u>接着，你需要扪心自问一下，自己的python基本功吼不吼啊？</u></b></p>
 <blockquote data-pid="LyDnC0b_">
  <b>吼啊！</b>——OK，开始欢快地学习爬虫吧 ！
  <br><b>不吼？你还需要学习一个！</b>赶紧回去看廖雪峰老师的教程，
  <br>
  2.7（更新：现在需要了解3.x了）的。至少<u>这些功能和语法</u>你要有基本的掌握 ：
 </blockquote>
 <ul>
  <li data-pid="-cs3Gvte"><b>list，dict：</b>用来序列化你爬的东西</li>
  <li data-pid="ICU_HjJ9"><b>切片：</b>用来对爬取的内容进行分割，生成</li>
  <li data-pid="-bkUVeQy"><b>条件判断（if等）：</b>用来解决爬虫过程中哪些要哪些不要的问题</li>
  <li data-pid="01t2E_Jc"><b>循环和迭代（for while ）：</b>用来循环，重复爬虫动作</li>
  <li data-pid="G9uIa1A-"><b>文件读写操作（open，close等）：</b>用来读取参数、保存爬下来的内容等</li>
  <li data-pid="vRmhkaZb"><b>编码常识（codecs等）：</b>非常关键，爬虫写熟了以后遇到的各种古怪问题，很多来自于UTF-8 GBK等奇奇怪怪的编码！这个问题先做了解，后面调试时候再解决也不迟！</li>
 </ul>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="A3CAgpqw">||<br>
   ||<br>
   V</p>
 <p data-pid="ibFEU2id"><b><u>然后，你需要补充一下下面几个内容，作为你的知识储备：</u></b><br>
  （注：这里并非要求“掌握”，下面讲的两点，只需要先了解，然后通过具体项目来不断实践，直到熟练掌握）</p>
 <p data-pid="7fkmcJc3"><b><u>1、网页的基本知识：</u></b></p>
 <blockquote data-pid="BI-hJhU_">
  基本的HTML语言知识（知道href等大学计算机一级内容即可）
  <br>
  理解网站的发包和收包的概念（POST GET）
  <br>
  稍微一点点的js知识，用于理解动态网页（当然如果本身就懂当然更好啦）
 </blockquote>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="6rahqLni"><b><u>2、一些分析语言，为接下来解析网页内容做准备</u></b></p>
 <blockquote data-pid="KcOHekIH">
  NO.1 正则表达式：扛把子技术，总得会最基础的：
  <br>
 </blockquote>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/69c995e57e29ab383d0717211e8f1c8e_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="799" data-rawheight="1719" data-original-token="69c995e57e29ab383d0717211e8f1c8e" class="origin_image zh-lightbox-thumb" width="799" data-original="https://pica.zhimg.com/69c995e57e29ab383d0717211e8f1c8e_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="AOwc72eG">NO.2 XPATH：高效的分析语言，表达清晰简单，掌握了以后基本可以不用正则<br>
  参考：<a href="https://link.zhihu.com/?target=http%3A//www.w3school.com.cn/xpath/" class=" wrap external" target="_blank" rel="nofollow noreferrer">XPath 教程</a></p>
 <figure data-size="normal">
  <img src="https://pica.zhimg.com/50/83020a6e8bfc4d3c38f7c36377da0d46_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="612" data-rawheight="255" data-original-token="83020a6e8bfc4d3c38f7c36377da0d46" class="origin_image zh-lightbox-thumb" width="612" data-original="https://pic1.zhimg.com/83020a6e8bfc4d3c38f7c36377da0d46_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="JfHMfqXn">NO.3 Beautifulsoup：<br>
  美丽汤模块解析网页神器,一款神器，如果不用一些爬虫框架（如后文讲到的scrapy），配合request，urllib等模块（后面会详细讲），可以编写各种小巧精干的爬虫脚本<br>
  官网文档：<a href="https://link.zhihu.com/?target=http%3A//beautifulsoup.readthedocs.org/zh_CN/latest/" class=" wrap external" target="_blank" rel="nofollow noreferrer">Beautiful Soup 4.2.0 文档</a> <b>参考案例：</b></p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/5d5b7de4dcaf69fa89ab4f5ef8bdbf3f_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="734" data-rawheight="267" data-original-token="5d5b7de4dcaf69fa89ab4f5ef8bdbf3f" class="origin_image zh-lightbox-thumb" width="734" data-original="https://pica.zhimg.com/5d5b7de4dcaf69fa89ab4f5ef8bdbf3f_r.jpg?source=1940ef5c">
 </figure>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/4a1f7a23745479544a88a42f20748856_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="737" data-rawheight="551" data-original-token="4a1f7a23745479544a88a42f20748856" class="origin_image zh-lightbox-thumb" width="737" data-original="https://pica.zhimg.com/4a1f7a23745479544a88a42f20748856_r.jpg?source=1940ef5c">
 </figure>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="GTqS45YA">No4. JSONpath</p>
 <p data-pid="Ety6Ali3">￼￼抓包类的爬虫（通常是动态网页），往往需要json的加持。jsonpath便应运而生，和xpath一样，它是快速检索分析各种各样json文件中待抓取内容的重要方法。</p>
 <p data-pid="9buO3naE">更多官方文档看此：<a href="https://link.zhihu.com/?target=https%3A//goessner.net/articles/JsonPath/" class=" wrap external" target="_blank" rel="nofollow noreferrer">JSONPath - XPath for JSON</a></p>
 <figure data-size="normal">
  <img src="https://pica.zhimg.com/50/v2-f50b82259741268aa84c3ceffff58bf4_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="685" data-rawheight="459" data-original-token="v2-1813d0d4e2406f3d4436da79107eee65" data-default-watermark-src="https://picx.zhimg.com/50/v2-53b705e725546fd1a0712a7b4c9efd16_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="685" data-original="https://picx.zhimg.com/v2-f50b82259741268aa84c3ceffff58bf4_r.jpg?source=1940ef5c">
 </figure>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="JcHVQdfY">||</p>
 <p data-pid="TmVXfO8D">||</p>
 <p data-pid="FvwcoCPq">V</p>
 <p data-pid="Kw7kwnU7"><b><u>接着，你需要一些高效的工具来辅助</u></b></p>
 <p data-pid="mm7XEpxj"><b>（同样，这里先了解，到具体的项目的时候，再熟悉运用）</b></p>
 <blockquote data-pid="HUORaO6C">
  <b>NO.1 F12 开发者工具：</b>
 </blockquote>
 <ul>
  <li data-pid="cT7_L6pr">看源代码：快速定位元素<br></li>
  <li data-pid="rVd8g3SE">分析xpath：1、此处建议谷歌系浏览器,可以在源码界面直接右键看</li>
 </ul>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/8be689bc054b6fc2077feca4b99d056e_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="861" data-rawheight="449" data-original-token="8be689bc054b6fc2077feca4b99d056e" class="origin_image zh-lightbox-thumb" width="861" data-original="https://pic1.zhimg.com/8be689bc054b6fc2077feca4b99d056e_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="sK7Ra8IW"><b>NO.2 抓包工具：</b></p>
 <ul>
  <li data-pid="bHfNOGMq">推荐httpfox，火狐浏览器下的插件,比谷歌火狐系自带的F12工具都要好，可以方便查看网站收包发包的信息</li>
 </ul>
 <figure data-size="normal">
  <img src="https://pica.zhimg.com/50/e1c9d44b06a3b9d199c62f0c0e84c3b8_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="893" data-rawheight="627" data-original-token="e1c9d44b06a3b9d199c62f0c0e84c3b8" class="origin_image zh-lightbox-thumb" width="893" data-original="https://picx.zhimg.com/e1c9d44b06a3b9d199c62f0c0e84c3b8_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="led038zG"><b>NO.3 XPATH CHECKER (火狐插件）：</b><br>
  非常不错的xpath测试工具，但是有几个坑，都是个人踩过的，，在此告诫大家：<br>
   1、xpath checker生成的是绝对路径，遇到一些动态生成的图标（常见的有列表翻页按钮等），飘忽不定的绝对路径很有可能造成错误，所以这里建议在真正分析的时候，只是作为参考<br>
   2、记得把如下图xpath框里的“x:”去掉，貌似这个是早期版本xpath的语法，目前已经和一些模块不兼容（比如scrapy），还是删去避免报错<br></p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/87c0ab00e3397e0bf8418b0fd693c298_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="700" data-rawheight="408" data-original-token="87c0ab00e3397e0bf8418b0fd693c298" class="origin_image zh-lightbox-thumb" width="700" data-original="https://pic1.zhimg.com/87c0ab00e3397e0bf8418b0fd693c298_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="Y4o7hrWX"><b>NO.4 正则表达测试工具：</b> <a href="https://link.zhihu.com/?target=http%3A//tool.oschina.net/regex/" class=" wrap external" target="_blank" rel="nofollow noreferrer">在线正则表达式测试</a> ，拿来多练练手，也辅助分析！里面有很多现成的正则表达式可以用，也可以进行参考！</p>
 <p data-pid="u4Cb5-t6">||</p>
 <p data-pid="SUvNdtYH">||</p>
 <p data-pid="9_Rl4Vkm">V</p>
 <p data-pid="5nPJEitD"><b><u>ok！这些你都基本有一些了解了，现在开始进入抓取时间，上各种模块吧！python的火，很大原因就是各种好用的模块，这些模块是居家旅行爬网站常备的——</u></b></p>
 <blockquote data-pid="_1LYNL_7">
  urllib
  <br>
  urllib2
  <br>
  requests
 </blockquote>
 <p data-pid="2_KRMUIt">||</p>
 <p data-pid="drbYSaMR">||</p>
 <p data-pid="Kr0Jh4ay">V</p>
 <p data-pid="vUGm1Zf6"><b><u>不想重复造轮子，有没有现成的框架？</u></b></p>
 <blockquote data-pid="ZvY4nEAU">
  华丽丽的scrapy
  <br>
  pyspider
 </blockquote>
 <p data-pid="2nqLhrS1">||</p>
 <p data-pid="6457zwcx">||</p>
 <p data-pid="-yll4Sl_">V</p>
 <p data-pid="lh9OYLrt"><b><u>遇到动态页面怎么办？</u></b></p>
 <blockquote data-pid="RFUCRDgP">
  selenium（会了这个配合scrapy无往不利，是居家旅行爬网站又一神器!）
  <br>
  phantomJS（不显示网页的selenium）
  <br>
  puppyteer（node.js乱入hhh）
  <br>
  （进阶）Browsermob-proxy （利用抓包的方式进行抓取，类似fiddler，比较复杂，但是足够好玩，可以解决很多意想不到的问题，高阶玩法！
 </blockquote>
 <p data-pid="fAz-COPF">||</p>
 <p data-pid="-w1bEnDq">||</p>
 <p data-pid="X-NueWxK">V</p>
 <p data-pid="CQD5DSnu"><b><u>遇到反爬虫策略验证码之类咋整？（不想折腾的直接第四个）</u></b></p>
 <blockquote data-pid="Xg83sV1r">
  PIL
  <br>
  opencv
  <br>
  pybrain
  <br>
  打码平台
 </blockquote>
 <p data-pid="IAoWMKOB">||<br>
  ||<br>
  V</p>
 <p data-pid="jEt2R-vQ"><b><u>然后是数据库，这里我认为开始并不需要非常深入，在需要的时候再学习即可</u></b></p>
 <blockquote data-pid="hFmB0v5D">
  mysql
  <br>
  mongodb
  <br>
  sqllite
 </blockquote>
 <p data-pid="4fAU3Qzq"><b>||</b></p>
 <p data-pid="MbEWIAQB"><b>||</b></p>
 <p data-pid="5vHX8EE5"><b>V</b></p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="w-oEaG7I"><b><u>爬来的东西怎么用？</u></b></p>
 <blockquote data-pid="AyDadySE">
  numpy 数据分析，类似matlab的模块，计算数据，处理矩阵
  <br>
  pandas（基于numpy的数据分析模块，相信我，如果你不是专门搞TB级数据的，这个就够了）
  <br>
  #更高阶段↓ML！
  <br>
  pytorch
  <br>
  tensorflow
 </blockquote>
 <p data-pid="LFICRP1W"><b>||</b></p>
 <p data-pid="iytgE56v"><b>||</b></p>
 <p data-pid="f-3tLObw"><b>V</b></p>
 <p data-pid="0FaBAjCw"><b><u>其他进阶技术</u></b></p>
 <blockquote data-pid="tY3Bzvqs">
  多线程、分布式
 </blockquote>
 <p data-pid="S4Q8UdG3">———————————— 乱入的分割线 —————————————</p>
 <p data-pid="xoym9S1f">然后学习编程关键的是学以致用，天天捧一本书看不如直接上手操练，下面我通过实际的例子来讲解爬虫——</p>
 <p data-pid="l0kZZQjj">比如最近，楼主在豆瓣上认识了一个很可爱的妹子，发现她一直会更新签名和日志，所以没事就会去她主页看看，但一直没有互相加好友（作为一只高冷的天蝎，怎么可以轻易加好友嘛！而且加了好友，你更新什么都会收到推送，那多没意思啊！一点神秘感都没有了！），可还是想及时获得妹子的最新动态，怎么办？</p>
 <figure data-size="normal">
  <img src="https://pica.zhimg.com/50/dd6fd1c0cb91ebad9bacd7d11a56bd09_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="400" data-rawheight="400" data-original-token="dd6fd1c0cb91ebad9bacd7d11a56bd09" class="content_image" width="400">
 </figure>
 <p data-pid="5G6R1AxF">于是我就写了个70几行的python脚本，包含爬虫+邮件模块，跑在家里的一台闲置笔记本上，通过计划任务每准点抓取妹子的签名和最新文章一次，发送到我的邮箱。。嗯，其实是很简单的技术，，代码如下所示：</p>
 <div class="highlight">
  <pre><code class="language-csharp"><span class="err">#</span><span class="p">-*-</span><span class="n">coding</span><span class="p">:</span><span class="n">utf</span><span class="p">-</span><span class="m">8</span><span class="p">-*-</span> <span class="err">#编码声明，不要忘记！</span>
<span class="n">import</span> <span class="n">requests</span>  <span class="err">#这里使用</span><span class="n">requests</span><span class="err">，小脚本用它最合适！</span>
<span class="k">from</span> <span class="n">lxml</span> <span class="n">import</span> <span class="n">html</span>    <span class="err">#这里我们用</span><span class="n">lxml</span><span class="err">，也就是</span><span class="n">xpath的方法</span>

<span class="err">#豆瓣模拟登录，最简单的是</span><span class="n">cookie</span><span class="err">，会这个方法，</span><span class="m">80</span><span class="p">%</span><span class="err">的登录网站可以搞定</span>
<span class="n">cookie</span> <span class="p">=</span> <span class="p">{}</span> 

<span class="n">raw_cookies</span> <span class="p">=</span> <span class="err">''#引号里面是你的</span><span class="n">cookie</span><span class="err">，用之前讲的抓包工具来获得</span>

<span class="k">for</span> <span class="n">line</span> <span class="k">in</span> <span class="n">raw_cookies</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="sc">';'</span><span class="p">):</span>
    <span class="n">key</span><span class="p">,</span><span class="k">value</span> <span class="p">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">"="</span><span class="p">,</span> <span class="m">1</span><span class="p">)</span>
    <span class="n">cookie</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="p">=</span> <span class="k">value</span> <span class="err">#一些格式化操作，用来装载</span><span class="n">cookies</span>

<span class="err">#重点来了！用</span><span class="n">requests</span><span class="err">，装载</span><span class="n">cookies</span><span class="err">，请求网站</span>
<span class="n">page</span> <span class="p">=</span> <span class="n">requests</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="err">'#妹纸的豆瓣主页#'</span><span class="p">,</span><span class="n">cookies</span><span class="p">=</span><span class="n">cookie</span><span class="p">)</span>

<span class="err">#对获取到的</span><span class="n">page格式化操作</span><span class="err">，方便后面用</span><span class="n">XPath来解析</span>
<span class="n">tree</span> <span class="p">=</span> <span class="n">html</span><span class="p">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">page</span><span class="p">.</span><span class="n">text</span><span class="p">)</span>

<span class="err">#</span><span class="n">XPath解析</span><span class="err">，获得你要的文字段落！</span>
<span class="n">intro_raw</span> <span class="p">=</span> <span class="n">tree</span><span class="p">.</span><span class="n">xpath</span><span class="p">(</span><span class="err">'</span><span class="c1">//span[@id="intro_display"]/text()')
</span><span class="c1"></span>
<span class="err">#简单的转码工作，这步根据需要可以省略</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">intro_raw</span><span class="p">:</span>
    <span class="n">intro</span> <span class="p">=</span> <span class="n">i</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="err">'</span><span class="n">utf</span><span class="p">-</span><span class="m">8</span><span class="err">'</span><span class="p">)</span>

<span class="n">print</span> <span class="n">intro</span> <span class="err">#妹子的签名就显示在屏幕上啦</span>

<span class="err">#接下来就是装载邮件模块，因为与本问题关联不大就不赘述啦</span><span class="p">~</span>


</code></pre>
 </div>
 <p data-pid="BaM8d4ui">怎么样~是不是很简单~</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="uPdszWS-">======</p>
 <div class="highlight">
  <pre><code class="language-text">v1.5更新日志：
增加一些新的技术方法，更多细节技术具体实现欢迎关注我，我会在专栏中更新
V1.2更新日志：
修改了一些细节和内容顺序</code></pre>
 </div>
 <p></p>
</body>