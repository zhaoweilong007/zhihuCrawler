# 为什么样本方差（sample variance）的分母是 n-1？
- 点赞数：14230
- 更新时间：2019年05月16日22时48分48秒
- 回答url：https://www.zhihu.com/question/20099757/answer/658048814
<body>
 <p data-pid="60XT0EVe">非常好的问题，探索这个问题的答案，不仅能更好的了解自己和这个世界，还能避免被征收<b>“偏差税”Bias Tax</b>！</p>
 <p data-pid="zUeBzAIc">先说结论，样本标准差的分母写成n-1，是为了对自由度进行校正，这叫<b>贝塞尔校正</b>（Bessel's Correction）[1]。注意这个贝塞尔不是贝塞尔曲线（Bézier curve）那个贝塞尔。</p>
 <p data-pid="3HRtU2c3">为了让中学水平的读者就能理解，我尽量不用公式，用浅显的语言和生活中的案例，来叙述这个问题的来龙去脉。这算是对其他答案的补充，也许看完后，再看其他高手的回答就没那么难了。</p>
 <p data-pid="bszSybeA">在统计领域，你经常会看到，为了减少干扰数据对结论的影响，数学家设计了大量的技术手段来对数据进行校正。</p>
 <p data-pid="M8PZAEYM">先看一篇我改编的故事《比尔盖茨冲进酒吧》：</p>
 <p data-pid="dsqsUgXN">一天晚上，小镇酒吧里坐着9个人，大家都是小镇上的工薪族，年薪的平均值在5万美元左右。</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-b43c8fd8e8fbae307442d58a81b5032b_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1298" data-rawheight="470" data-original-token="v2-6e7956ddf49a6b867b7810394e43ec2b" data-default-watermark-src="https://picx.zhimg.com/50/v2-de33092e8714f0b92185d2a01651b9d3_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1298" data-original="https://picx.zhimg.com/v2-b43c8fd8e8fbae307442d58a81b5032b_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="ygyLfz_B">从上面的数据和图表，你可以看出50000美元这个平均值，比较准确的体现了9个人的收入水平。</p>
 <p data-pid="uf661yHi">正在此时，比尔盖茨急匆匆的走进酒吧，冲向厕所……</p>
 <p data-pid="VbtdPGnK">假如比尔盖茨的年薪是10亿美元，在他上厕所的时间里，另外9个人啥也没做，加上比尔盖茨，10个人的平均年薪平均值一下子从5万爆涨到1亿美元。</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-2caa10c42416196d000ecf8cc9ceebad_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1330" data-rawheight="1415" data-original-token="v2-c4a7abcfcd39fde6bf98eba7416cc29d" data-default-watermark-src="https://picx.zhimg.com/50/v2-ca331be99ee1e59c71d75285a4ffc7b6_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1330" data-original="https://pic1.zhimg.com/v2-2caa10c42416196d000ecf8cc9ceebad_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="_gOJ0xSO">如图，相比之下，和比尔盖茨相比，9人的年薪太渣，完全看不出高度，像二向箔一样薄。</p>
 <p data-pid="T5YBdNzA">而当比尔盖茨离开后，他们还是啥也没做，平均年薪却暴跌了近1亿美元。</p>
 <p data-pid="tQ_O7ne0">9人抱头哭死在厕所……</p>
 <p data-pid="Q8j4bvxi">剧终^_^</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="oswaUGya">在这个例子里，比尔盖茨就是一个干扰数据，因为他的存在，让平均值的计算并不能体现酒吧里工薪族的<b>真实</b>平均水平，9人的平均年薪无缘无故的涨到了1亿。当然这个数也无法体现比尔盖茨的真实收入水平，因为他缩水到了1亿。</p>
 <p data-pid="kcEyFM0m">那统计学家应该怎么办呢？</p>
 <p data-pid="Wq881KPC">在统计上，把比尔盖茨这种干扰数据称为异常值（Outlier）。</p>
 <p data-pid="IYVdBZJL">应对这种异常值，最简单的方法就是排除掉它们。在计算平均值时把比尔盖茨排除掉，就无法干扰平均值了。（当然实际应用比较复杂，排除异常值需要谨慎，不能随意的排除）</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="fUbbj5wB">排除法这种技术手段也经常应用在比赛打分上。</p>
 <p data-pid="XLDdQkUn">我们知道裁判打分的主观性非常大，为了减少单个教练的影响，比赛通常会安排多个裁判一起给选手打分，然后再取一个平均值。</p>
 <p data-pid="IYK7uIAA">但实际上在求平均值时，还会再去掉最高分和最低分，然后对剩下的分数计算平均值。</p>
 <p data-pid="NKN56tDl">这种排除最高/低分的手段也是为了消除干扰，因为最高分和最低分对平均值的影响比较大，会大幅偏离真实的水平。</p>
 <p data-pid="dDl_7hpW">例如，下面是10个裁判的打分</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-617061ebeb1f13233a224eddc45e41b3_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1303" data-rawheight="729" data-original-token="v2-f7f3def338249f77f44da3019f002df8" data-default-watermark-src="https://picx.zhimg.com/50/v2-d2eb28b10b22df3e0640030c2ad12b17_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1303" data-original="https://picx.zhimg.com/v2-617061ebeb1f13233a224eddc45e41b3_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="W1WzRdpX">上图中最高分把选手的平均值拉高了0.60分，你可能会说，这点分数不算啥，应该影响不大。</p>
 <p data-pid="v5V506Ds">但在实际的比赛中，选手的差距通常非常的小，0.1分都会对选手的排名产生显著的影响。</p>
 <p data-pid="pIO4fUF2">为了尽可能消除其干扰，得到一个相对客观的平均值，通常在计算平均值时，会排除掉最低分和最高分，这样算出来的平均值叫裁剪平均值（Truncated mean）。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="HIeOcrkP">比尔盖茨和去掉最高/低分的这两个例子，都是为了说明统计领域的校正技术，用排除法来消除掉干扰数据的影响。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="tSPPlUZ4">现在你也可能意识到了，在样本方差的计算上，分母使用（n-1），而不是n，也是一种排除法来消除干扰的技术手段。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="YjmnHsOz"><b>为什么要减去1，这个1代表的是哪个数？</b></p>
 <p data-pid="E6WfuFo0">这个减去的1，不特指任何一个数，1代表那个失去“独立客观”的维度（自由度）。</p>
 <p data-pid="qVaan8OD">看不明白？</p>
 <p data-pid="Kku-QT3n">正常，听我慢慢解释。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="PVzBr5t7">在我们在对全体进行采样时，有一个至关重要的前提条件，就是一定要<b>随机</b>采样，这其中的关键词是随机。</p>
 <p data-pid="nWRAEh4U">之所以要随机，这是为了避免出现样本偏差。因为如果样本错了，后面的计算步骤即使全部都正确，最终结果也是错的。</p>
 <p data-pid="ZGcp91mH">例如，要想回答“中国人是不是喜欢吃狗肉？”的问题。</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-b5e102aa9f948085680119af7a20e625_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="500" data-rawheight="493" data-original-token="v2-695f423c45f679bf8315423012853c49" data-default-watermark-src="https://pic1.zhimg.com/50/v2-560ee676f9672c165d96569e3b7fdc66_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="500" data-original="https://picx.zhimg.com/v2-b5e102aa9f948085680119af7a20e625_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="HawmVZpu"><b>请问，以下两个采样，哪一个能得到客观的结论？</b></p>
 <ul>
  <li data-pid="MIO6MQnl">只去玉林狗肉节上采样。</li>
  <li data-pid="QvP2IFZK">对中国人进行时间和地点都随机的采样。</li>
 </ul>
 <p data-pid="CSrcLumr">两种采样方法，会得出截然相反的结论。</p>
 <ul>
  <li data-pid="Dw8H6vdL">前一种采样很<b>不自由</b>，被限制在一个极其有限的时空里。</li>
  <li data-pid="Gs5QadTt">后一种采样有充分的<b>自由</b>，跳出限制，可以没有干扰的随机采样。</li>
 </ul>
 <p data-pid="BuW1FwV8">如果只在玉林采样，这个样本就是偏差样本（Biased Sample），是不具代表性的样本（Unrepresentative Sample）。</p>
 <p data-pid="En9mDdsX">如果根据这个偏差样本，得出了“中国人居然吃狗肉，太野蛮了！”的结论。无论在逻辑上如何完美，最终结论也是荒谬的。</p>
 <p data-pid="45Are89Z">这就是所谓的<b>“垃圾进，垃圾出”（Garbage in ， garbage out）</b>[2]</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="WGC5pf2n">你在玉林采样越多，你的偏见就会越深，只会进一步的<b>固化你的偏见</b>。</p>
 <p data-pid="x7BGIbKG">但自由的随机采样，你采样越多，你的偏见就会越来越少，看到更真实、<b>更多样化</b>的中国人。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="IEYBMRBU">在这里需要暂停一下：</p>
 <p data-pid="i1MyM4Uv">请大家反思一下，自己是不是也曾犯过同样的错误，取错了样本，出现了偏差或偏见（Bias）？</p>
 <p data-pid="RCo_oUyK">反正，我经常会犯这样的错误，轻易就相信传言[3]，或轻易给别人扣上帽子[4]，这都是偏见。</p>
 <p data-pid="D1Cb-aJ_">（罪过，罪过，宽恕我吧，我知道自己错了！）</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="80B_FXGy"><b>我们普通人经常会因为样本偏差，被收取“偏差税”(Bias Tax)</b></p>
 <p data-pid="GgMtuGFO">例如彩票，就是利用了人们的这一弱点。</p>
 <p data-pid="ZSYwj3Su">彩民们只注意到了那些极少数获得大奖的人，看不到绝大数人赔钱。</p>
 <p data-pid="WN4BPahw">越是盯着那些获奖的人看，彩民们的偏见越深，越是坚信自己会中奖。</p>
 <p data-pid="dQc9pQaC">他们因为在选取样本时出现偏差，而被别人收税。</p>
 <p data-pid="nDqeaEMb">好吧，我承认，偏差税这个词是我根据智商税这个词编造出来的(^_-)。</p>
 <p data-pid="ZsdR0AEa">很多人喜欢用智商税这个词来嘲笑犯错的人智商低，但智商税这个词是有偏差的。</p>
 <p data-pid="E7v5dtCM">因为不能根据一个事件就推算出一个人整体的智商，这是不具代表性的有偏样本，这是偏见。</p>
 <p data-pid="GzAs9-SU">例如很多彩民的智商很高，他们使用各种复杂的公式，做了大量复杂的计算，他们的智商一点都不低，他们的问题是出在样本偏差上。</p>
 <p data-pid="N0f6gbsk">而偏差税这个词和智商税不一样，不论我们的智商高低，人人都会有偏见，事事都会出偏差，这个税每个人都在交。</p>
 <p data-pid="hryVqQ3h">例如，股票市场上的散户，迷信中医和保健品的大爷大妈，轻信谣言的吃瓜群众，……，几乎无人可以幸免，都在为样本偏差付出代价。</p>
 <p data-pid="95EuRsva">推荐一个TED演讲《<a href="https://link.zhihu.com/?target=https%3A//www.ted.com/talks/alan_smith_why_we_re_so_bad_at_statistics/transcript%3Flanguage%3Dzh-cn%23t-757755" class=" wrap external" target="_blank" rel="nofollow noreferrer">为什么应该热衷于统计学</a>》。</p>
 <p data-pid="XvJutUfg">看完就知道人们对这个世界的偏差有多大了。</p>
 <p data-pid="fxhMOBZL">所以人们不是智商出了问题，是在选取样本时出现了偏差，所以偏差税是一个更客观（无偏）的词。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="IfZHiMlP">其实，不仅是普罗大众，就是那些权倾一时的政治家，也曾为样本偏差付出过惨重的代价。</p>
 <p data-pid="_LKpsJhX">1948年美国大选，大部分报纸都预测杜威会战胜杜鲁门，当选美国总统。社会舆论一致看好杜威，以至于竞选当天，杜威认为杜鲁门很快就会打电话庆祝他当选。</p>
 <p data-pid="pO9S6OoF">但竞选结果却大跌眼镜，最终是杜鲁门当选。（是不是有些似曾相识？）</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-47a3c80f67b50207b76cfb87a72e8c9a_720w.jpg?source=1940ef5c" data-size="normal" data-rawwidth="1280" data-rawheight="720" data-original-token="v2-450d5f1e2f442dc1156a6b6672fe61de" data-default-watermark-src="https://picx.zhimg.com/50/v2-ef8759ff011c83f7bbfc17faee0a1ec3_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://picx.zhimg.com/v2-47a3c80f67b50207b76cfb87a72e8c9a_r.jpg?source=1940ef5c">
  <figcaption>
   杜鲁门获胜后，兴高采烈的举着那些提前预测杜威击败杜鲁门的报纸，笑得好真诚啊！
  </figcaption>
 </figure>
 <p data-pid="4GQ-tDGi">图片来源：<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3Dh4uUV1klrkM" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">youtube.com/watch?</span><span class="invisible">v=h4uUV1klrkM</span><span class="ellipsis"></span></a></p>
 <p data-pid="_Kv_hWdj">这次的预测之所以会失败，是因为调查机构通过电话调查的方式做的采样。</p>
 <p data-pid="9om05iB-">1948年，虽然电话已发明多年，但价格并不便宜，有电话的多是相对富裕的家庭，多数人的家里没有普及电话。也就是说，这种采样是有偏差的，只反映了富裕阶层的观点，无法反映当时主流选民的意愿，也就是统计出现了样本偏差。[5]</p>
 <p data-pid="pqmunXqt">在当时，除了很多美国人被误导，还有一个人也因为这个样本偏差，把所有筹码错压在了杜威的身上，结果却因此而丢掉了整个江山，此人就是蒋介石。本来杜鲁门在做副总统时就对蒋介石印象很差，在他当选后，更是变本加厉，很快减少了对蒋介石的援助。[6]</p>
 <p data-pid="u7mcQV5L">常凯申也哭死在厕所！</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="hjcKTuWQ">事实上，有太多的<b>仇恨、歧视、偏见和武断</b>的观点，是建立在样本偏差的垃圾数据之上的<b>。</b></p>
 <p data-pid="atfbXuJJ">因为“垃圾进，垃圾出”，无论人们如何雄辩，逻辑上如何完美，算法上如何先进，结论也是一堆错误的垃圾。[7]</p>
 <p data-pid="XDOB94se">这是值得你、我、以及所有人都应该警惕的现象。</p>
 <p data-pid="D5-g1izB">例如：你想知道当代日本人是怎样的。就不能只对抗日神剧进行采样，不能只对日本右翼进行采样，要获得真实的数据，必须去日本实地对日本人进行<b>随机</b>采样。</p>
 <p data-pid="3VNuGBgc">只有采样是随机，是不带偏差的（Unbiased），才能保证自己吃进去的不是垃圾信息，这是得出正确结论的第一步。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="IjT-flPq"><b>只要人人都追求无偏差，世界会变成美好的人间</b></p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="6osJ83FV">除了要做到采样是随机的，还要确保<b>样本之间是互相独立的</b>，在统计上用<b>自由度（Degrees of freedom）</b>来描述这种独立性。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="ztmWWE9X">我们以常见的招投标为案例，解释一下独立性。</p>
 <p data-pid="iAjDFipy">有个学校要盖教学楼，邀请几个建筑公司来投标。学校希望建筑公司的报价尽可能低，而且还要确保质量。所以学校不能只选价格最低的方案，而是要挑选出综合评分最优的方案。</p>
 <p data-pid="cumLyqPx">要做到公正客观的评分，必须确保几件事：</p>
 <p data-pid="q7ZJQ85C">首先，学校不能让内部员工来评分，因为内部员工和项目有直接的利益关系，员工都希望自己在项目中获得更多利益，做不到评分上客观独立。</p>
 <p data-pid="5VKWls-4">所以学校只能从外部请专家来评标，因为外人<b>独立</b>于学校之外，会减少直接利益所产生的影响。</p>
 <p data-pid="vmzU5Bp5">于是学校计划邀请3个专家来评审，让专家对建筑公司的方案和报价进行综合评分。</p>
 <p data-pid="0fzyfwN4">其次，学校在挑选专家时，要尽可能确保这些专家之间的观点也必须是互相<b>独立</b>的，不能人云亦云。</p>
 <p data-pid="bd6oMfVj">假如其中1人是另外2人的上级，那上级说话，下级的观点就倾向于和上级保持一致，在评分时无法做到独立，这样的评分是有偏差的。花了3个专家的钱，却成了1个专家的一言堂。专家独立性从3变成了1，这偏差也太大了。</p>
 <p data-pid="HU9MNopD">最后，学校还必须确保，任何一个专家都没有被建筑公司收买，是<b>独立</b>于建筑公司，没有利益输送的。</p>
 <p data-pid="kiR2zHvI">如果被收买了，专家就会修改评分，让贿赂的商家胜出，这个专家的数据也是不独立客观的。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="JVDVecLJ">从上面的这个案例里，你会发现<b>独立的重要性</b>，一旦出现利益关联，独立性就会降低，数据必然会出现偏差。</p>
 <p data-pid="O44PmP9I">类似的制度设计非常的广泛，例如陪审团制度，就设计了大量的机制来保证陪审团成员的独立性。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-f7edffa84fb78ce60db25379cfa304e3_720w.jpg?source=1940ef5c" data-size="normal" data-rawwidth="1940" data-rawheight="1092" data-original-token="v2-8d9e6612cc4c9e75961a067c2ceda1ee" data-default-watermark-src="https://pic1.zhimg.com/50/v2-2c507bd48ef5eb67f74b857a2fc4ea87_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1940" data-original="https://picx.zhimg.com/v2-f7edffa84fb78ce60db25379cfa304e3_r.jpg?source=1940ef5c">
  <figcaption>
   电影《十二怒汉》剧照
  </figcaption>
 </figure>
 <p data-pid="BEfkfQQg">推荐重温一下《十二怒汉》这部经典，看看人们的偏见（Bias）是如何的根深蒂固，消除偏见是如何的困难。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="2Xp9IudS"><b>几千年来，人类为了提高独立性，殚精竭虑的设计了各种精巧的制度，这些制度历久弥坚，逐渐成为了现代社会的基石。</b></p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="ofxBc5la">在统计实践中人们发现，偏差的产生，很多时候也是因为样本数据之间出现了<b>各种隐含的关联关系</b>，降低了数据之间的独立性。</p>
 <p data-pid="mMOHrpol">而解决的策略还很清晰，就是发现其中隐含的关联关系，然后进行校正。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="D5GLmIHt">让我们再回到样本方差（Sample Variance）的分母（n-1）上来。</p>
 <p data-pid="GiMnFiMv">你既然在看这个问题，那就已经知道了方差<img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D" alt="\sigma^{2}" eeimg="1">的计算公式</p>
 <p data-pid="63hnA_dw"><img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D%3D+%5Cfrac%7B++%28x_%7B1%7D-%5Cmu%29+%5E%7B2%7D%2B%28x_%7B2%7D-%5Cmu%29+%5E%7B2%7D%2B...%2B%28x_%7Bn%7D-%5Cmu%29+%5E%7B2%7D+%7D+%7Bn%7D" alt="\sigma^{2}= \frac{  (x_{1}-\mu) ^{2}+(x_{2}-\mu) ^{2}+...+(x_{n}-\mu) ^{2} } {n}" eeimg="1"></p>
 <p data-pid="tjQXM56s">需要注意的是这里的方差<img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D" alt="\sigma^{2}" eeimg="1">其实是<b>全体</b>的方差，μ是<b>全体</b>的平均值，n是<b>全体</b>变量的数量</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="G8Q9ulBS">例如一家啤酒厂每天生产1万瓶啤酒，我们想知道这些啤酒的质量差异性如何，可以打开这1万瓶啤酒测量，再把所有测量结果代入到上面的公式里求方差，在计算中，没有漏下任何一瓶啤酒的数据。</p>
 <p data-pid="KgoDWhwK">你也发现了，这样做不仅麻烦了，而且成本极高。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="fynyedhl">更好方法是对出厂的啤酒进行随机的采样，计算这部分样本的方差<img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1">。</p>
 <p data-pid="8ylCV4Wf">例如，随机的从产品中找出100瓶，用这100瓶来估算1万瓶啤酒的质量差异，注意，除了这100瓶的数据，其他9900瓶啤酒数据是完全未知的。</p>
 <p data-pid="EZfwUxaO">样本方差<img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1">它是从全体数据中随机取出一小部分所做的计算，用这个局部的100瓶啤酒的方差去估计全体1万瓶啤酒的方差。</p>
 <p data-pid="zkzhyJr9"><img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D%3D+%5Cfrac%7B++%28x_%7B1%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D%2B%28x_%7B2%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D%2B...%2B%28x_%7Bn%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D+%7D+%7Bn-1%7D" alt="s^{2}= \frac{  (x_{1}-\bar{x}) ^{2}+(x_{2}-\bar{x}) ^{2}+...+(x_{n}-\bar{x}) ^{2} } {n-1}" eeimg="1"></p>
 <p data-pid="MZD3xZzz"><br>
  上面这个样本方差<img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1">公式，尽管在形式上和全体方差<img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D" alt="\sigma^{2}" eeimg="1">的公式近似，但是内涵上发生了天翻地覆的变化。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="U2Omhi05">我们来比较一下，全体方差<img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D" alt="\sigma^{2}" eeimg="1">和样本方差<img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1">：</p>
 <p data-pid="ZEyWUM-E">全体方差 <img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D" alt="\sigma^{2}" eeimg="1"> 是一个客观<b>事实（Fact），</b>是对所有个体数据的全体所作的客观描述（Describe）。</p>
 <p data-pid="l1wW8ebt">而样本方差 <img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1"> 更像一个<b>观点（Opinion）</b>，是我们根据少量抽样个体的数据，对全体所作出的估算（Estimation），或者说是预测。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="eLYymbji">既然样本方差 <img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1"> 不是一个事实，而是一个观点，是一种估算，为了让这个估算尽可能的接近事实，就必须注意样本不要出现偏差（Bias），否则就会“垃圾进，垃圾出”，得出错误的估算。</p>
 <p data-pid="lSBp-da1">例如</p>
 <ul>
  <li data-pid="5WsYDjA4">我们不能只对某批产品取样，某个特定时间取样，我们的随机取样必须尽可能的覆盖所有批次，取样要有充分的自由度，足够的随机。</li>
  <li data-pid="HwJ8YOzJ">另外还要注意，避免样本里的变量之间存在隐含的关联关系。</li>
 </ul>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="3lQG0s5B">我们来看一个例子</p>
 <p data-pid="MQPhsO_o">假设随机抽出的样本里只有两个数 <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+x1%2Cx2+%5Cright%5C%7D" alt="\left\{ x1,x2 \right\}" eeimg="1"></p>
 <p data-pid="x_si5G3i">如果这2个数是独立和随机抽取的，<b>你就不能从x1猜出x2，</b>例如我告诉你x1=10，请问x2等于多少？</p>
 <p data-pid="rgkTxP45">你根本猜不出来，因为随机抽取让x2和x1之间没有关联。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="EzeXWpoB">但是，没想到的是，因为一个数据的存在，让这个随机取样产生了一个隐含的关联关系。</p>
 <p data-pid="e6rBGhxP">这个数就是计算样本方差 <img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1">时，需要用到的<b>样本平均值 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1"></b>，他的引入让随机抽取的独立性和自由度减少了一点点。</p>
 <p data-pid="AN95aLPK">因为样本平均值 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">引入了一些信息，让x1和x2之间不再是相互独立的关系了。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="v97vuot7">根据平均值公式</p>
 <p data-pid="Dyxr141D"><img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D%3D%5Cfrac%7Bx_%7B1%7D%2Bx_%7B2%7D%7D%7B2%7D" alt="\bar{x}=\frac{x_{1}+x_{2}}{2}" eeimg="1"></p>
 <p data-pid="6h_0mDB4">只要知道了x1和<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">，就可以计算出x2的值。</p>
 <p data-pid="CBYjl8HA">如果x1=10，<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">=10，那x2=10</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="3JaAIOjk">同样，知道了x2和<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">，就可以计算出x1的值。</p>
 <p data-pid="nh3KMpgX">如果x2=10，<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">=11，那x1=12</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="NBI2YUaI">也就是说，出问题的并不是x1或者x2，这两个数本来好好的，互相独立的。出问题的是平均值<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">，他引入的新信息，让样本数据之间的独立性减少了，关联性增加了。</p>
 <p data-pid="eiMCqQwE">或者还可以说，在平均值的介入下，x1和x2的自由度降低了，原来是两个独立的数，现在只有一个独立了，另一个则不再自由，好像有些人云亦云了。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="F6oET-lG">同样的，对于更多的样本量：</p>
 <p data-pid="KNo04rwq">如果样本是3个数 <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+x_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%5Cright%5C%7D" alt="\left\{ x_{1},x_{2},x_{3}\right\}" eeimg="1"></p>
 <p data-pid="uMseiTyN">则知道了x1，x2，就能通过<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">，计算出x3，独立性或者说自由度，就从3降到了2。</p>
 <p data-pid="3VWJLu6I">如果样本是4个数 <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+x_%7B1%7D%2Cx_%7B2%7D%2Cx_%7B3%7D%2Cx_%7B4%7D%5Cright%5C%7D" alt="\left\{ x_{1},x_{2},x_{3},x_{4}\right\}" eeimg="1"></p>
 <p data-pid="Ioy6jV24">则知道了x1，x2，x3，就能通过<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">，计算出x4，独立性或者说自由度，就从4降到了3。</p>
 <p data-pid="3RTXKGcr">……</p>
 <p data-pid="P8wh_8N3">如果样本是n个数 <img src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7B+x_%7B1%7D%2Cx_%7B2%7D%2C...%2Cx_%7Bn%7D%5Cright%5C%7D" alt="\left\{ x_{1},x_{2},...,x_{n}\right\}" eeimg="1"></p>
 <p data-pid="5R9zeVFF">则知道了x1，x2,..., <img src="https://www.zhihu.com/equation?tex=x_%7Bn-1%7D" alt="x_{n-1}" eeimg="1"> ，就能通过<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">，计算出 <img src="https://www.zhihu.com/equation?tex=x_%7Bn%7D" alt="x_{n}" eeimg="1"> ，独立性或者说自由度，<b>就从n降到了n-1。</b></p>
 <p data-pid="XvSwwm9N">平均值<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">让样本的独立性或自由度减少了1，导致了样本出现了偏差。</p>
 <p data-pid="SyWoeiEL">这就是为什么样本方差的分母不是n，也不是n-2或n-3，而是n-1的原因。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="6yWq_xyW"><b>自由度变小会对样本方差产生什么影响呢？</b></p>
 <p data-pid="-JQCK-5Z">这意味着，样本方差会变小。</p>
 <p data-pid="xdmg03_x">我们知道，方差是通过计算样本和平均值之间的距离，来描述样本的<b>分散程度</b>，数据之间差异越大，方差越大，数据之间越是趋同，方差越小。</p>
 <p data-pid="NkRUH1bY">还是用专家评分的案例来解释：</p>
 <p data-pid="Nf-9Q3h0">如果专家组中，所有人都独立，每个人的评分会出现较大的差异性。</p>
 <p data-pid="Ze7frOlw">但如果专家组中有个领导，他自己没有任何主见，只是在看完大家的评分之后，取个折中的评分，是个老好人型的领导。</p>
 <p data-pid="uBqLUBcd">请注意，这个领导没有贡献任何新观点，他的观点<b>不独立</b>，只是重复了别人的观点，但这个重复数据污染了整体数据的独立性，让原本差异性较大数据，因为折中数据的出现，减少了差异，或者说，出现了一些趋同效应，这就产生了偏差。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="C9RTkZkv">回到样本方差 <img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1"> 上，因为样本平均值 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1"> 就是根据样本来计算的，样本平均值 <img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1"> 成了那个贡献重复数据的领导，让原来独立的、随机的、没有偏差的样本数据，<b>在计算加工过程中引入了偏差</b>，减少了数据之间的差异性，这种趋同效应让样本方差 <img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1"> 变小。</p>
 <p data-pid="Ka5ReWpQ">也就是说，数据取样没问题，是无偏的。但是在后来的方差计算中，均值的引入，让差异性减少，<b>本来无偏的数据出现了偏差</b>。<b>样本方差会一直小于总体方差，这是一个有偏样本方差。</b><br></p>
 <p data-pid="5Ztcicur"><img src="https://www.zhihu.com/equation?tex=s_%7Bbiased%7D%5E%7B2%7D%3D+%5Cfrac%7B++%28x_%7B1%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D%2B%28x_%7B2%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D%2B...%2B%28x_%7Bn%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D+%7D+%7Bn%7D" alt="s_{biased}^{2}= \frac{  (x_{1}-\bar{x}) ^{2}+(x_{2}-\bar{x}) ^{2}+...+(x_{n}-\bar{x}) ^{2} } {n}" eeimg="1"></p>
 <p data-pid="iB3G4HH7">上面是有偏差的样本方差公式，是没有经过校正的。<br></p>
 <p data-pid="PkvMTQ9J">普鲁士天文学家贝塞尔（Bessel）在对海量的观测数据做计算时，也注意到了这个偏差。</p>
 <p data-pid="mM-2D4Ne">这个偏差的特点是：</p>
 <ul>
  <li data-pid="ieiqRTfw">在样本量小的时候偏差影响比较明显，样本方差比全体方差偏小。</li>
  <li data-pid="A3166hzX">但是当样本量增大时，偏差逐渐减少，直到影响可以忽略不计。</li>
 </ul>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="Nz5K7qZ7">既然样本方差变小了，那干脆让分母变小，增大样本方差就行了。</p>
 <p data-pid="jHKz-dvd">贝塞尔给出了修正方法，即把样本方差公式的分母修正为n-1，所以这个修正被后人称为贝塞尔校正。</p>
 <p data-pid="m9_3Px9B"><img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D%3D+%5Cfrac%7B++%28x_%7B1%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D%2B%28x_%7B2%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D%2B...%2B%28x_%7Bn%7D-%5Cbar%7Bx%7D%29+%5E%7B2%7D+%7D+%7Bn-1%7D" alt="s^{2}= \frac{  (x_{1}-\bar{x}) ^{2}+(x_{2}-\bar{x}) ^{2}+...+(x_{n}-\bar{x}) ^{2} } {n-1}" eeimg="1"></p>
 <p data-pid="HpMDVBsv">具体的公式推导过程，可以看Emory University的这篇关于Bessel's Correction推导的文章 [8]</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-cf2e4b3a33f167ccfba6767a16797a00_720w.jpg?source=1940ef5c" data-size="normal" data-rawwidth="900" data-rawheight="761" data-original-token="v2-e487ba2c523af6d4a1ac22ceb68408ed" data-default-watermark-src="https://pica.zhimg.com/50/v2-1b95680ed20b4fa7c0d4c83c8363913d_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="900" data-original="https://picx.zhimg.com/v2-cf2e4b3a33f167ccfba6767a16797a00_r.jpg?source=1940ef5c">
  <figcaption>
   德国天文学家和数学家弗里德里希·威廉·贝塞尔
  </figcaption>
 </figure>
 <p data-pid="srEhnfvp">图片出处：<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%25BC%2597%25E9%2587%258C%25E5%25BE%25B7%25E9%2587%258C%25E5%25B8%258C%25C2%25B7%25E5%25A8%2581%25E5%25BB%2589%25C2%25B7%25E8%25B4%259D%25E5%25A1%259E%25E5%25B0%2594" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/wiki/%</span><span class="invisible">E5%BC%97%E9%87%8C%E5%BE%B7%E9%87%8C%E5%B8%8C%C2%B7%E5%A8%81%E5%BB%89%C2%B7%E8%B4%9D%E5%A1%9E%E5%B0%94</span><span class="ellipsis"></span></a></p>
 <p data-pid="VAwbc1h1">样本方差<img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1">公式里的分母n-1，就是这么来的，那个减去的1，就是用来校正<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">所带来的偏差，他不代表某一个样本，而是对自由度的补偿，让缩小的样本方差重新变大一点。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="ZhapvV6a"><b>样本方差偏小是不是采样出现问题？因为越接近平均值，就越容易被采样？</b></p>
 <p data-pid="S5A2tgoB">从直觉上好像是这样的，比如下面的这个鱼类长度的分布，数据聚集在平均值106（蓝线）附近，如果采样，在平均值周围的确有更大的概率被采样到。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-9581c8cc2bcd428950333276d9fbcc44_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1572" data-rawheight="718" data-original-token="v2-1a299cf32d6b2a8e14f454bcec947412" data-default-watermark-src="https://picx.zhimg.com/50/v2-7442749281630bf7b5c7a1c177d4fd0c_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1572" data-original="https://pic1.zhimg.com/v2-9581c8cc2bcd428950333276d9fbcc44_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="21zkqKZ6">但是，<b>直觉是靠不住的。</b>上面的分布只是一种，还有很多的分布，其数据不在平均值附近，而是分散在四处。</p>
 <p data-pid="PcQNvq_F">例如，下面这个西班牙流感死亡年龄的分布</p>
 <figure data-size="normal">
  <img src="https://pica.zhimg.com/50/v2-90a964739c241cf6b35b91fa5700a625_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1590" data-rawheight="662" data-original-token="v2-d19bddeb1a21261e52b3418a64da8118" data-default-watermark-src="https://picx.zhimg.com/50/v2-16c242b146f47f366cc2e51ed85813b9_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1590" data-original="https://pic1.zhimg.com/v2-90a964739c241cf6b35b91fa5700a625_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="_mJoMBF0">数据并没有聚集在平均值43附近，如果取样，就会发现样本更大的概率是远离平均值，而不是在平均值附近。</p>
 <p data-pid="OoUydyuL">所以样本方差出现偏小的原因，并不是因为平均值附近被采样到的概率更大，这只在部分情况下成立，在很多情况下并不成立。</p>
 <p data-pid="FJ3j0c_J"><b>样本方差出现偏差的原因和采样无关</b>，也和平均值附近更容易被采样无关，因为在很多情况下，远离平均值的数据更容易被采样到，这无法解释样本方差为什么会比全体方差小。</p>
 <p data-pid="UIzn8yNf">更好的解释是，计算过程中引入样本平均值，降低了样本的自由度，减少了数据的差异性。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="CBKqIZ82">所以直觉也是靠不住的，事实上，有太多的偏差和偏见（Bias）是由直觉贡献的。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="uIjARrYz"><b>结论</b></p>
 <ul>
  <li data-pid="GfWF2YVW">样本标准差的分母写成n-1，是为了对数据进行校正，这叫贝塞尔校正（Bessel's Correction）。</li>
  <li data-pid="dpgBxYY2">统计经常用各种方法来消除掉干扰数据的影响，例如比尔盖茨和去掉最高/低分的这两个例子。</li>
  <li data-pid="OIUTmxQ8">样本数据之间也经常会出现各种隐含的关联关系，降低了数据之间的独立性或自由度（Degrees of freedom），这会让样本更聚集，让样本偏差变小。</li>
  <li data-pid="Oj2rh_L-">样本方差<img src="https://www.zhihu.com/equation?tex=s%5E%7B2%7D" alt="s^{2}" eeimg="1">公式里的分母n-1，就是校正样本平均值<img src="https://www.zhihu.com/equation?tex=%5Cbar%7Bx%7D" alt="\bar{x}" eeimg="1">所减少的自由度，样本数据本身没有偏差，是计算过程中引入的新信息（样本均值），让计算结果出现了偏差。</li>
 </ul>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="H_nJtS-p"><b>推荐阅读</b></p>
 <p data-pid="Akq86iMl">[1]<a href="https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Bessel%2527s_correction" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">en.wikipedia.org/wiki/B</span><span class="invisible">essel%27s_correction</span><span class="ellipsis"></span></a></p>
 <p data-pid="uH2ODEKX">[2]<a href="https://link.zhihu.com/?target=https%3A//heap.io/blog/data-stories/garbage-in-garbage-out-how-anomalies-can-wreck-your-data" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">heap.io/blog/data-stori</span><span class="invisible">es/garbage-in-garbage-out-how-anomalies-can-wreck-your-data</span><span class="ellipsis"></span></a></p>
 <p data-pid="vIqJN-ZO">[3]<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E8%25BB%25BC%25E4%25BA%258B%25E8%25AD%2589%25E6%2593%259A" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/wiki/%</span><span class="invisible">E8%BB%BC%E4%BA%8B%E8%AD%89%E6%93%9A</span><span class="ellipsis"></span></a></p>
 <p data-pid="5lNDHtxG">[4]<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E4%25BB%25A5%25E5%2581%258F%25E6%25A6%2582%25E5%2585%25A8" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/wiki/%</span><span class="invisible">E4%BB%A5%E5%81%8F%E6%A6%82%E5%85%A8</span><span class="ellipsis"></span></a></p>
 <p data-pid="jSK6sO84">[5]<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/1948%25E5%25B9%25B4%25E7%25BE%258E%25E5%259B%25BD%25E6%2580%25BB%25E7%25BB%259F%25E9%2580%2589%25E4%25B8%25BE" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/wiki/1</span><span class="invisible">948%E5%B9%B4%E7%BE%8E%E5%9B%BD%E6%80%BB%E7%BB%9F%E9%80%89%E4%B8%BE</span><span class="ellipsis"></span></a></p>
 <p data-pid="gPoNaO9P">[6]<a href="https://link.zhihu.com/?target=http%3A//www.todayonhistory.com/lishi/201705/62790.html" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://www.</span><span class="visible">todayonhistory.com/lish</span><span class="invisible">i/201705/62790.html</span><span class="ellipsis"></span></a><br><br>
  [7]<a href="https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%2581%258F%25E5%25B7%25AE%25E6%25A8%25A3%25E6%259C%25AC" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">zh.wikipedia.org/wiki/%</span><span class="invisible">E5%81%8F%E5%B7%AE%E6%A8%A3%E6%9C%AC</span><span class="ellipsis"></span></a></p>
 <p data-pid="tjAWM31H">[8]<a href="https://link.zhihu.com/?target=http%3A//math.oxford.emory.edu/site/math117/besselCorrection/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">math.oxford.emory.edu/s</span><span class="invisible">ite/math117/besselCorrection/</span><span class="ellipsis"></span></a></p>
</body>