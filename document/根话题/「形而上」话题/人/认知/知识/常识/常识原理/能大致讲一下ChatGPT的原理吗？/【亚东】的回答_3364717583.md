# 能大致讲一下ChatGPT的原理吗？
- 点赞数：5914
- 更新时间：2024年05月10日16时47分10秒
- 回答url：https://www.zhihu.com/question/598243591/answer/3364717583
<body>
 <p data-pid="GmT-Jtnw">当今<b>活着</b>的<b>最聪明</b>的几个人之一，也是最硬核的思考者之一，<b>Wolfram</b>写的《<b>这就是ChatGPT</b>》应该能解释的最准确，最清晰吧！毕竟他是费曼学习法的创始人<b>费曼的亲学生</b>。在离开学术界时，费曼给他的信里写的是：“你不会理解普通人的想法的，他们对你来说着只是傻瓜”！</p>
 <p data-pid="XNBvA7BS">但是Wolfram写的这个说明很好懂！真的是非常准确的面向善于掌握真正的东西的人！</p>
 <h2>ChatGPT能做什么？为什么能做到？</h2>
 <p data-pid="YZBZNfA8">ChatGPT的核心功能是生成文本，它通过预测文本序列中下一个最可能出现的词来做到这一点。也就你输入一段文字 既提示词（Prompt）后，它把这一段文字做为一个文本序列的开头，然后在它的后面开始一个词一个词的“生成”。所以评估ChatGPT及其它LLM的模型有一个叫 Token/s，也就是一秒能生成多少个词。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-bb149fd9872d51e94cd685d9c5d7ed7c_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="446" data-rawheight="125" data-original-token="v2-bb149fd9872d51e94cd685d9c5d7ed7c" data-default-watermark-src="https://picx.zhimg.com/50/v2-746f6d846fca2ad80787edeb82fc340b_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="446" data-original="https://pic1.zhimg.com/v2-bb149fd9872d51e94cd685d9c5d7ed7c_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="UIFMCPYl">为什么能做到呢？ ChatGPT的能力来自于它（神经网络模型）在大量文本数据上的预训练。通过这种训练，神经网络学习到了语言的模式和结构，使其能够生成连贯的和且语义上合理的文本。这就有个问题，实际上ChatGPT是不了解内容、概念与知识的。但是能保证在生成文本时“关注”输入序列的不同部分，从而更好地捕捉语言的上下文和含义。</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-e84e5a6163be72461d701511f1b34bad_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="645" data-rawheight="162" data-original-token="v2-e84e5a6163be72461d701511f1b34bad" data-default-watermark-src="https://picx.zhimg.com/50/v2-6bd196616080ed19e89fd5e108bcbe13_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="645" data-original="https://picx.zhimg.com/v2-e84e5a6163be72461d701511f1b34bad_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="KwWBw-we">同样的，生成文本时采用了一种策略，即不仅仅选择概率最高的词，而是在一定温度（温度参数调节随机性）下选择，以增加文本的多样性和创造性。也就是同一个Prompt得到的不是同一个结果，但是差异不大的原因。</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-476b1356bd8f5903973750121f58eb66_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="693" data-rawheight="193" data-original-token="v2-476b1356bd8f5903973750121f58eb66" data-default-watermark-src="https://pic1.zhimg.com/50/v2-1f066d17881c34d8d6cdc9166fdfc0a8_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="693" data-original="https://picx.zhimg.com/v2-476b1356bd8f5903973750121f58eb66_r.jpg?source=1940ef5c">
 </figure>
 <h2>神经网络模型是什么？</h2>
 <p data-pid="X32I-v2p">神经网络模型是一种受人脑结构启发的计算模型，它通过模仿人脑中的神经元网络来处理信息。人脑是由大约1000亿个神经元组成的复杂器官，这些神经元通过数万亿个连接（称为突触）相互沟通。当多个神经元相互连接形成一个复杂的网络时，就构成了神经网络。这些网络通过电信号的形式处理和传递信息。</p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-97764b0fb8aeb981570028bb64b9bf40_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="462" data-rawheight="372" data-original-token="v2-97764b0fb8aeb981570028bb64b9bf40" data-default-watermark-src="https://picx.zhimg.com/50/v2-479e88a1ade4bd6546d507659c17e35f_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="462" data-original="https://pica.zhimg.com/v2-97764b0fb8aeb981570028bb64b9bf40_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="FOI5Ydcy">神经网络由大量的“神经元”组成，这些神经元通过“连接”相互沟通。每个连接都有一个权重，类似于人脑中神经元之间的信号强度。神经网络通常有多个层，信息会在这些层之间传递。在ChatGPT中，信息会通过一系列层，每一层都会对信息进行处理，逐步提炼和理解文本的含义。就像人会学习一样，神经网络通过训练来学习，训练过程中会不断调整神经元之间的连接权重。训练使用了大量的文本样本，神经网络会尝试生成与这些样本相似的文本。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-873e8a198f0e8b2d799d022e4500ed06_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="584" data-rawheight="219" data-original-token="v2-873e8a198f0e8b2d799d022e4500ed06" data-default-watermark-src="https://picx.zhimg.com/50/v2-aca8842f429679e2801e417e3844b5ae_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="584" data-original="https://pica.zhimg.com/v2-873e8a198f0e8b2d799d022e4500ed06_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="oNzzM4cM">但是跟人脑的学习与应用机制不一样的是，在ChatGPT的神经网络推理（日常使用）中，信息通常是单向传递的，即从输入层到隐藏层，最后到输出层（前馈）。学习或者修改权重需要的是专门的操作训练（既学习），这样神经网络也可以包含反馈机制，允许信息反向流动，以改进预测和生成文本的能力。</p>
 <p data-pid="pdaz0z3w">看到这儿了，你有没有更强烈的了解一下这个东西的原理是什么？你怎么样更好的掌握它，应用在你的工作、开发的日常中去呢？我推荐大家还是听听行业大佬的讲解，正好知乎知学堂最近新推出的这门《<b>AI 大模型进阶之旅</b>》公开课，正是适应当下AI大模型发展而推出的，<b>深入讲解GPT和AI</b>大语言模型（LLM）工具的原理，讲解神经网络模型，从理论实践，带你全程体验大模型微调过程。目前这个课还是免费阶段，建议先去<b>占坑领取</b>，<b>入口就是下面这个↓ ↓ ↓</b></p><a data-draft-node="block" data-draft-type="edu-card" data-edu-card-id="1767138638247546880"></a>
 <p data-pid="Qfnu1Xe7"><b>神经网络学习的是直接的文字吗？</b></p>
 <p data-pid="bH9H_6yh">在ChatGPT的神经网络中，直接用于学习的不是“文本序列”，是文本序列变化得到的“Token、令牌、词元”。而嵌入技术就是一种将词汇或短语转换成数值形式（通常是向量）的方法。这些数值表示能够捕捉词汇的语义特征，即它们的含义和用法。通过嵌入，每个词汇都被放置在一个高维的“语义空间”中。在这个空间里，语义上相似的词汇会彼此靠近，而意思相差较远的词汇则相距较远。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-2e492420139952592562843fd7d20498_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="770" data-rawheight="575" data-original-token="v2-2e492420139952592562843fd7d20498" data-default-watermark-src="https://picx.zhimg.com/50/v2-6b91db75e8b91b74bdfea080651c743b_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="770" data-original="https://pic1.zhimg.com/v2-2e492420139952592562843fd7d20498_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="wEBPApiD">嵌入向量可以进行数学运算，如向量加法和乘法，这些运算有助于模型理解词汇之间的关系，比如“国王”和“女王”的嵌入向量相减，可能得到与“男性”和“女性”相减相似的结果。</p>
 <p data-pid="rKQu-cnM">嵌入又使得神经网络能够根据上下文理解词汇的多种含义。例如，单词“bank”在不同的上下文中可以指河岸或金融机构，嵌入可以帮助模型区分这些不同的用法。</p>
 <p data-pid="pMr5YNLO">所以在ChatGPT中，嵌入是生成文本的基础。模型使用嵌入向量来预测下一个最合适的词，从而生成连贯的句子和段落。</p>
 <h2>现在呢，我总结的结果是：</h2>
 <p data-pid="sI5W31Bq">它是文字知识的高维压缩。</p>
 <p data-pid="G9LXca7a">举一些数据： GPT-3的训练用了 4000 亿 token，也就大概是 3500 多亿文字。 GPT-4 的训练用了 13 万亿的 token, 也就是大概 10 万亿文字相当（可能有大量的图像与视频数据）。 LLAMA2的训练用了 2 万亿 token，也就是大概 1.5 万亿文字。</p>
 <p data-pid="s82q0dRz">所以简单的从数据上看，这样的训练已经到了人类可用的电子化数据的极限了吧，尤其是文字类的数据吧，大概已经没有什么太多的渠道得到更多的数据了。</p>
 <p data-pid="QF9Rydlh">所以我们认为LLM 把人类的知识都压缩到了一个模型里，我认为是非常正确的一个认知。</p>
 <p data-pid="XPpwKb7v">这个压缩是一个数据从低维表示到高维映射，再从高维映射到低维表示的操作。这个映射是一种有损或者更像一种，你从低维空间操作一个工具去获取高维的信息，能获得多少，除了这个映射有多丰富，还与你的技巧有关系。你的手法越准确(Prompt)越好，你能获得的越多。更像是钓鱼，你知道那里有鱼，但是能不能钩到最好的鱼？？？期望你是邓刚！</p>
 <h2>最后介绍一下作者：</h2>
 <p data-pid="cFzY4k3h">斯蒂芬·沃尔夫勒姆（英语：Stephen Wolfram，1959年8月29日—活着），是计算机科学、数学、理论物理方面的著名英国科学家。他编写了著作《一种新科学》。同时，他还是著名大学伊利诺伊大学厄巴纳-香槟分校的兼职教授。2012年，他成为美国数学协会的院士。</p>
 <p data-pid="EKUASKSo">17岁进入<b>牛津大学</b>。 1978年未获得学位离开进入<b>加州理工大学</b>，次年，才20岁的他获得了粒子物理学博士学位。 他的论文答辩委员会由<b>理查德·费曼</b>、Peter Goldreich、Frank J. Sciulli 和 Steven Frautschi组成，并且由Richard D.Field主持。1981年，沃尔弗拉姆获得<b>麦克阿瑟天才奖</b>。</p>
 <p data-pid="T-O6oS3J">作为商人，他是软件公司沃尔夫勒姆研究公司的创立者和首席执行官。在公司内部，他是数学软件 Mathematica（与Matlab，Maple并称数学3M） 和计算型知识引擎 Wolfram Alpha 的主要设计师。他近期的工作主要是基于知识的编程，把 Mathematica 编程语言进一步拓展为 Wolfram 语言。他的相关著作《Wolfram 语言入门》的英文版发行于2015年。在学术上，他以粒子物理学、元胞自动机、宇宙学、复杂性理论、计算机代数系统上的研究成果闻名于世。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-703c1cbef6ac9e674f03ce592c6c9978_720w.jpg?source=1940ef5c" data-size="normal" data-rawwidth="140" data-rawheight="200" data-original-token="v2-703c1cbef6ac9e674f03ce592c6c9978" data-default-watermark-src="https://picx.zhimg.com/50/v2-703c1cbef6ac9e674f03ce592c6c9978_720w.jpg?source=1940ef5c" class="content_image" width="140">
  <figcaption>
   聪明的脑袋都这样
  </figcaption>
 </figure>
 <p></p>
 <p></p>
 <p></p>
</body>