# 如何看待南京邮电大学学生2020申请到加州理工EE系唯一一个大陆PhD？
- 点赞数：5423
- 更新时间：2020年05月26日19时04分36秒
- 回答url：https://www.zhihu.com/question/396560251/answer/1242998067
<body>
 <p data-pid="PBCkUSsD">首先声明一下： 本回答只针对黄同学的这篇论文， 不针对其实验室和其他同学， 更不针对南邮这个学校。 我和南邮的其他学生也有交流过，大有脚踏实地者在， 希望大家不要一叶障目，以偏概全了。 但对于真正的造假沽名钓誉者，纵容他既是对自己多年拼搏的亵渎， 也是变向推动了劣币驱逐良币的恶果。 另外，也希望大家都是拿着真凭实据的揭发，而非恶意揣测的抹黑。 因为实锤一个人不该用谎言， 真相难道不够吗？</p>
 <p data-pid="4vA1g5HQ">======================</p>
 <p data-pid="dQ1aWgS3">因为之前有做过无线通信 + 深度学习的相关工作， 因此也有幸拜读了这位黄同学的“高作”。 我做的是5G毫米波的混合波束成形方向， 然后这位同学将深度学习和混合波束成形结合了一下， 发表了一篇高引的文章。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-dc2cdbf07a9cd9b18955a039109edf21_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="469" data-rawheight="123" data-original-token="v2-4c59e2f68d65ec46c38f4d03e7e4172d" data-default-watermark-src="https://picx.zhimg.com/50/v2-1346f00365e79500e551944b5aa8bd6a_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="469" data-original="https://picx.zhimg.com/v2-dc2cdbf07a9cd9b18955a039109edf21_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="7lUW9PYd">图是刚刚截的， 去年刚看到的时候还是10多的引用量， 现在已经100多了。 讲道理，搞无线通信的文章里有这个增长速度的， 绝对是高质量的经典论文了。 然而事实是怎样的呢？</p>
 <p data-pid="WE8TEU36">这篇文章可以说是Hybrid beamforming的耻辱， 是无线通信的耻辱。 我从大三开始做这个方向做到现在的博士阶段， 但是看完这篇文章， 深深刷新了我的三观。 全文的核心和本质其实就一句话：<b>通过一个深度学习的幌子， 来骗过那些既不懂深度学习又不懂hybrid beamforming的编辑和审稿人</b>。</p>
 <p data-pid="QNGiJRnZ">这篇文章有几大重要漏洞：</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-d9eb93c8358c547f21259eb944dc6db5_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="519" data-rawheight="299" data-original-token="v2-afd10441b3d13cd90d70e50376d6893e" data-default-watermark-src="https://pic1.zhimg.com/50/v2-b11e30e570852fc26b20d6ed6b31b73f_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="519" data-original="https://pica.zhimg.com/v2-d9eb93c8358c547f21259eb944dc6db5_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="zQtSWgBo">这是他的网络模型图， 光这个就离谱。 首先这个图就莫名其妙， 把物理模型和DNN网络模型混淆。 RF chain （射频链路）连着 神经网络？ 这是什么操作？？ 顺便一提， 射频链路上的是模拟信号， 神经网络是数字处理， RF chain后的数据是不可能直接输入网络的。 然后他说这个网络替代了analog precoder？？？ 我甚至怀疑黄某人是不是只知道analog precoder这个名词？？？ 这个precoder的要求是由相移器实现，也就是说每个元素的模必须为1， 你看你训练的网络能满足这个要求吗？？</p>
 <p data-pid="Ux5uwvn3">看到评论区有同学提到了还有一种可能性， 那就是他这图的意思是他相当于用硬件中的射频元件实现了神经网络部分。 那就相当于他线下训练了这个网络， 然后训练完成后将之用射频元件部署。 我其实有按这个思路理解过， 但感觉比我上面讲的这个更离谱就否定了，既然有人提出了我也回答一下： 如果是照这个思路的话有几个致命的问题： 1. 整个过程之中，<b>系统没有利用任何信道信息</b>。 信道信息相当于告知了基站，用户在哪， 我应该往哪发送， 传统的波束算法无不依赖于信道信息。 结果黄同学这个，是直接摸石头过河吗，相当于都不需要知道用户在哪个方位我就能设计波束了？ 信道估计领域也可以直接取消不用了？ 2. 用射频元件实现神经网络。 注意在RF chain之后的信号都是在射频上的， 那你想实现一个复数乘法，意味着需要一个相移器和一个放大器。 我也不考虑复数加法所需的加法器了和激活函数啥的硬件复杂度了。 光是这千百个神经元所涉及的复数乘法， 就没有硬件实现的道理。 （注意， 在射频上实现神经网络和在数字域实现的成本天差地别 ）</p>
 <p data-pid="8CcRVAVZ">结果人家还真训练了， 性能还真不错？？？</p>
 <p class="ztext-empty-paragraph"><br></p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-294f1147e64246663360039489719864_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="503" data-rawheight="395" data-original-token="v2-188cec43fc91e7adb21ce01a7cd203c7" data-default-watermark-src="https://picx.zhimg.com/50/v2-855d3b882e644946000e88d2a216a6f8_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="503" data-original="https://picx.zhimg.com/v2-294f1147e64246663360039489719864_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="mKlR2rYi">比传统Fully digital的性能，超出了5个db？？？恕我直言，这是在用深度学习突破物理极限， 香农再世也弄不出这样的性能。</p>
 <p data-pid="cgSD1OsZ">通俗地解释下这个fully digital beamforming算法和答主所提出的hybrid beamforming算法的区别， 就是前者是后者的成本的数十倍， 理论上前者的性能是后者的上界。 后者相当于牺牲了一定的性能换取了更低廉的成本。 结果在这个仿真图里他这样吊打fully digital的性能， 让后者情何以堪？ 4G LTE时代研究了多年的digital beamforming可以全部推导了，直接神经网络大法好 （反正性能我画了算）。 另外提一句， 19年的时候，hybrid beamforming已经有许多经典的工作了， 但是文章中只有选了最早的14年的一篇 （可以算是最差的）进行对比， 我觉得真的熟悉这个领域的作者，至少会再拿出其他几篇经典之作的性能比较一下。</p>
 <p data-pid="_FkRaF6A">接着说文章的漏洞，</p>
 <p class="ztext-empty-paragraph"><br></p>
 <figure data-size="normal">
  <img src="https://pic1.zhimg.com/50/v2-7f9ce9a40a09f18e70484a2fb4b6e334_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="517" data-rawheight="111" data-original-token="v2-4c03cf541fcf98e76cef9bb82c4a3bac" data-default-watermark-src="https://pica.zhimg.com/50/v2-c0258d6b257d3e2a9bebc3b953f845af_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="517" data-original="https://pic1.zhimg.com/v2-7f9ce9a40a09f18e70484a2fb4b6e334_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="BXiuKIwh">他用mse作为损失函数训练， 目的就是让网络去逼近他的标签。 然后他的仿真图告诉我们说， 他的性能比标签的还要好上5-10个db？？？如果说别的网络有拟合损失， 这个网络是有拟合增益的效果吗？？</p>
 <p data-pid="b5sdT54H">我觉得黄某人就差把： 我的结果都是伪造的 写在文章上了。</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="dUJcvgTQ">=================</p>
 <p data-pid="KHxEe1YF">评论区有答主补充了， 复杂度分析也是问题的，我去回看了一下，确实。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-fa4e951b6298473dc9cf68f9768bb803_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="512" data-rawheight="86" data-original-token="v2-bb42044e2b0d763ece08033c9b3fcdcd" data-default-watermark-src="https://picx.zhimg.com/50/v2-01562530eeb2749f5b34328b511f9975_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="512" data-original="https://picx.zhimg.com/v2-fa4e951b6298473dc9cf68f9768bb803_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="zXZkGyk0">[3]这篇文章算是真正的HBF的开山之作了， 但他这里的复杂度里， 可以看到计算复杂度是 <img src="https://www.zhihu.com/equation?tex=N_r" alt="N_r" eeimg="1"> (接收天线数的7次方）。 这个7次方的复杂度是极其离谱的。 在我所知的[3]的算法中，无论如何都是算不出这样的复杂度的，正常的分析应该是2-3次方，而且结果必与射频链路数有关（ <img src="https://www.zhihu.com/equation?tex=N_%7BRF%7D" alt="N_{RF}" eeimg="1"> ）这个7次方我不知道是怎么出来的, 我严重怀疑作者是否真的看过[3]。 如果连[3]都没有看过的话，个人认为应该是没有资格做HBF的。</p>
 <p data-pid="wgbjJF54">=================</p>
 <p data-pid="WBqo0wop">哦， 还有文章中的“算法部分”，</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-798997154c70d423328649089ae7c55b_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="515" data-rawheight="729" data-original-token="v2-58212b964f371cabeb609c5de5b451ee" data-default-watermark-src="https://picx.zhimg.com/50/v2-d162759168e39c9c84fdd307e0530c87_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="515" data-original="https://pic1.zhimg.com/v2-798997154c70d423328649089ae7c55b_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="9zO6Jrpl">为不失公正我直接贴出原文截图了。 我是很少看到神经网络相关文章，把最基本的SGD算法用（13），（14），（15）这样的式子写出来的， 大部分的文章应该都认为这是一个不需要解释的东西， 然而除去引用总共就5页篇幅的这篇trans， 花了大半页来介绍这个SGD算法？哪怕是通信领域的没有CV领域那么专业， 也不至于19年了还要把SGD算法拿出来写一下作为自己的东西？ 况且这13，14式也离谱， 两个相同的v是什么意思？ 代表Ra和Rd每次的更新量是一样的，这是否太不严谨了？</p>
 <p class="ztext-empty-paragraph"><br></p>
 <p data-pid="EvwRpRlo">越写越气愤。 深度学习近年的崛起， 真的引来了太多水论文的人， 如何鉴别呢？ 文章只有一些似是而非的描述， 只有逻辑不通的模型， 只有生搬硬套的算法， 只有性能卓绝的仿真。 没有什么呢？ 没有人敢公布自己的代码。 一个不存在的东西， 又如何公布呢？</p>
 <p data-pid="2PK-rhH-">至少，我可以肯定黄的这篇论文， 根本不存在对应的仿真代码，因为他这个模型和算法， 都没有写出来的可能性，更不用谈跑通了。 逻辑上根本就是矛盾的。</p>
 <p data-pid="m9Odj7Hm">最后晒下和他的一次交流。</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-d10aff38c5ad86aeaf61862d7b3aef9a_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1265" data-rawheight="696" data-original-token="v2-9e64f84fa12427497eab5278e7450866" data-default-watermark-src="https://pic1.zhimg.com/50/v2-2622de1e494c775bcf8054bceef0742e_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1265" data-original="https://picx.zhimg.com/v2-d10aff38c5ad86aeaf61862d7b3aef9a_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="Iztef1vQ">姓名先打码了，怕被熟人认出来。 一开始读的时候我就感觉这篇文章很有问题， 因为我做的就是这个领域。 但是我当时觉得，也许是这人天赋异禀， 我未能参透其深意。 于是我写了封邮件询问其代码， 想着配合着代码再理一理就能读懂了。 当然无线通信很多人都不公开代码的， 结果没想到黄同学真的回信了。 然而信中其称这涉及和华为的保密协议，因此代码不能公开？？至于他给的那些建议，只能说呵呵了， 和没有说没啥区别，和文中的核心没有一点关系，属于百搭的话语，看上去没问题。</p>
 <p data-pid="kXNqrQwX">不过作者能回信，其实当时是给我留下了挺好的印象的，当时还年轻的我全部信以为真， 以为对方可能是真的大佬吧（虽然我觉得大佬应该不可能写出这个似是而非的文章），于是我就写了我觉得最核心的一个问题， 不给代码可以理解，回答下这问题可以吧~</p>
 <figure data-size="normal">
  <img src="https://picx.zhimg.com/50/v2-966b20836d969cf81124c3ccbaaeceae_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1201" data-rawheight="294" data-original-token="v2-819418d777ec963215438850299ad7ce" data-default-watermark-src="https://picx.zhimg.com/50/v2-3c9f5a941e14bd6f2748acca0ae88d5c_720w.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb" width="1201" data-original="https://picx.zhimg.com/v2-966b20836d969cf81124c3ccbaaeceae_r.jpg?source=1940ef5c">
 </figure>
 <p data-pid="OX-PtVDl">其实还有好几个问题，但想着先问下这个问题，因为如果他的损失函数真的如我理解的那样（也是他论文表达的意思我觉得）， 那他的性能真的是不可理喻， 拟合的结果超过了标签的性能。然而刚刚回复完我涉及华为保密的黄同学，再也没有回过我的信息了。 我也就无从问起了。 如果有看过这篇论文的读者应该可以知道，这个问题算是比较核心的问题了， 如果这个问题他没有好的答案，这篇论文本身上就是不该存在的。</p>
 <p data-pid="oMachjXf">我一度以为是他可能真有事情， 而不是学术造假因此不回我邮件了， 后来也淡忘了这事。 直到后来有一天一位国外的学长问我要相关领域的论文，我就和他说了下这篇论文， 告诉他我不太看得懂， 如果他看懂了可以和我交流下。 结果这学长当场和我说， 这个作者的论文以后不要看了， 都是造假的， 让我去知乎搜一下黄鸿基其人就知道了。</p>
 <p data-pid="T8GfUqCq">这件事当时刷新了我的三观， 没想到在一年后再次上了知乎热榜。</p>
 <p data-pid="t5MSMfRC">我理解那些引用他论文的人， 因为我也引用了。 没有办法，人在屋檐下，我自己的论文， 审稿人问我为什么不和他的这篇对比？ 我只能苦笑， 这样一份根本说不通，无法复现的论文，如何对比呢？ 但我也只能引用， 否则审稿人说： 你学术调研的不够， 连这么高引的论文都不引。 于是呢？ 恶性循环， 有黄某人的实验室团队先积累出前期引用率优势，后期其他人真的不引也得引。 想想也真的可悲， 我不是也为了问问题强行说出“this paper is well-written”的话吗？</p>
 <p data-pid="lpL6HL9r">最后，相关领域我推荐清华戴凌龙老师实验室的工作， 至少全部代码都是公开的， 扎实。 至于那些不公开代码的戴着深度学习帽子的无线通信论文， 恕我直言， 应该一律按伪造数据处理。</p>
 <p data-pid="3vXKkltN">要知道， 和无线通信结合的深度学习论文，本身网络方面就只是套用而已，基本没有太多的创新， 隐瞒代码也不会有什么好处， 无非是让人们更难实锤你的论文问题而已。 真的问心无愧者，有什么好心虚的呢？</p>
 <p data-pid="8-tRTmDm">第一次在知乎写这么长的回答， 也确实是有感而发， 不匿名了，如果觉得本回答有问题的， 支持直接对线。</p>
 <p data-pid="-W7C9265">====================================================</p>
 <p data-pid="-Ipii-EV">看到有说恶意索要代码，不给是正常的。 我也说过， 通信领域一贯以来许多工作不公开代码，恰恰留下了漏洞。 但私以为神经网络相关真的该全面公开，否则性能完全是自己说了算， 别人锤无可锤， 即使你说性能和文章不符， 作者回你一句： 你的训练有问题， XXX参数对不上， 你能和他对线几遍呢？ 而不像传统算法一样，很容易直接复现，然后推导啥的齐全。</p>
 <p data-pid="VxwipQyJ">一般公开的代码的，让别人能复现的论文， 更容易被follow。 只是没想到，这么无凭无据的工作， 也能轻轻松松上百的引用。 我自己实验室的导师， 是我见过学术上最正派，最公正的学者了。 曾经和学姐一起写的一篇论文里有个小漏洞，对全文思想几乎没有影响，只是一个次幂写错了， 还是在文章的复杂度计算的角落。 我们发现的时候，文章已经最后定稿接收了。 后来我导师知道了， 第一次狠狠批评了我们（他平时人特别nice， 一般都是和我们平等的商量讨论）， 和我们说， 让我们要用最快时间去核实这个错误， 如果真的有影响， 他要向编辑部申请撤稿重新修改。 后来是师姐去找了篇paper证明了那个错误没什么大问题，最后才作罢了。 我的导师做了很多踏踏实实的工作， 在学术上影响了我良多， 只是他的paper里也几乎没有上百引用的， 看到黄同学这么高的引用率和这么快的水文速度， 感到不平的同时，也只能在知乎里码码字了。 本人非常讨厌网暴，但我觉得用合理的证据来揭发这些学术乱象，也算是对中国科研的一点微小贡献吧。 应该把荣誉留给真正勤恳科研的老师们。</p>
 <p data-pid="lG0iwuvQ">有一个词我觉得很贴切，也深感害怕：劣币驱逐良币。</p>
 <p data-pid="qMjSDe1Z">另外我这篇也不是不给代码的问题了，我后来只问了一个文中涉及最核心的问题， 结果半小时前刚回复我的黄同学就杳无音讯了，如果没有问题的话，这个回答花费不了两分钟的时间。</p>
</body>